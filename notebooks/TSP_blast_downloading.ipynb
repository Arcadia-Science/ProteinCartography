{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Arcadia-Science/biofile.git@das/dev\n",
      "  Cloning https://github.com/Arcadia-Science/biofile.git (to revision das/dev) to /private/var/folders/5b/71_5djmd0p5_yhs0tpbbq68r0000gn/T/pip-req-build-oppr0wu3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/Arcadia-Science/biofile.git /private/var/folders/5b/71_5djmd0p5_yhs0tpbbq68r0000gn/T/pip-req-build-oppr0wu3\n",
      "  Running command git checkout -b das/dev --track origin/das/dev\n",
      "  Switched to a new branch 'das/dev'\n",
      "  branch 'das/dev' set up to track 'origin/das/dev'.\n",
      "  Resolved https://github.com/Arcadia-Science/biofile.git to commit 81d00b1dd02c3d259d234ce0d79df5aff6d82ac2\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading boto3-1.26.104-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting s3path\n",
      "  Using cached s3path-0.4.1-py3-none-any.whl (16 kB)\n",
      "Collecting awscli\n",
      "  Downloading awscli-1.27.104-py3-none-any.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting jsonpickle\n",
      "  Using cached jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n",
      "Collecting rsa<4.8,>=3.1.2\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting docutils<0.17,>=0.10\n",
      "  Using cached docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "Collecting botocore==1.29.104\n",
      "  Downloading botocore-1.29.104-py3-none-any.whl (10.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting PyYAML<5.5,>=3.10\n",
      "  Using cached PyYAML-5.4.1.tar.gz (175 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
      "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "Collecting colorama<0.4.5,>=0.2.5\n",
      "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/dennis/miniconda3/envs/umap/lib/python3.10/site-packages (from botocore==1.29.104->awscli->biofile==0.1.0.8) (1.26.15)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/dennis/miniconda3/envs/umap/lib/python3.10/site-packages (from botocore==1.29.104->awscli->biofile==0.1.0.8) (2.8.2)\n",
      "Requirement already satisfied: packaging in /Users/dennis/miniconda3/envs/umap/lib/python3.10/site-packages (from s3path->biofile==0.1.0.8) (23.0)\n",
      "Collecting smart-open\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dennis/miniconda3/envs/umap/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.29.104->awscli->biofile==0.1.0.8) (1.16.0)\n",
      "Building wheels for collected packages: biofile, PyYAML\n",
      "  Building wheel for biofile (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for biofile: filename=biofile-0.1.0.8-py3-none-any.whl size=6863 sha256=ed491c03ad6753589c65e4b1fafea8fb18f6822ec54d7a842cd4bff56d23ad6e\n",
      "  Stored in directory: /private/var/folders/5b/71_5djmd0p5_yhs0tpbbq68r0000gn/T/pip-ephem-wheel-cache-zgdqck9w/wheels/f0/a7/fb/115c72134a89ca7ca942fc003e02e9cf655f3de337584918ba\n",
      "  Building wheel for PyYAML (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyYAML: filename=PyYAML-5.4.1-cp310-cp310-macosx_10_9_x86_64.whl size=45662 sha256=fe2abfed0e9bb87b03728232885e0f7f2a9edcc89515a5fb07074f0cc26563e4\n",
      "  Stored in directory: /Users/dennis/Library/Caches/pip/wheels/c7/0d/22/696ee92245ad710f506eee79bb05c740d8abccd3ecdb778683\n",
      "Successfully built biofile PyYAML\n",
      "Installing collected packages: pyasn1, smart-open, rsa, PyYAML, jsonpickle, jmespath, docutils, colorama, botocore, s3transfer, boto3, awscli, s3path, biofile\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "Successfully installed PyYAML-5.4.1 awscli-1.27.104 biofile-0.1.0.8 boto3-1.26.104 botocore-1.29.104 colorama-0.4.4 docutils-0.16 jmespath-1.0.1 jsonpickle-3.0.1 pyasn1-0.4.8 rsa-4.7.2 s3path-0.4.1 s3transfer-0.6.0 smart-open-6.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/Arcadia-Science/biofile.git@das/dev --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local files will be saved in ../output/\n",
      "remote files will be saved in s3://arcadia-protein-evolution/cartography/tsp/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import biofile\n",
    "\n",
    "bfd = biofile.Dataset(identifier = 'TSP_Aam', \n",
    "                      local = '../output/', \n",
    "                      remote = 's3://arcadia-protein-evolution/cartography/tsp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 16844.59it/s]\n"
     ]
    }
   ],
   "source": [
    "input_files = [str(bfd.Local / i) for i in os.listdir(bfd.Local) if 'TSP' in i and '.txt' in i]\n",
    "output_files = [j.replace('.txt', '_blastp_results.out') for j in input_files]\n",
    "\n",
    "files_dict = dict(zip(input_files, output_files))\n",
    "\n",
    "for input_file, output_file in tqdm(files_dict.items()):\n",
    "    \n",
    "    if not os.path.exists(output_file):\n",
    "        !blastp -db nr -query {input_file} -out {output_file} -remote -max_target_seqs 50000 -outfmt 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_accessions = []\n",
    "\n",
    "for file in files_dict.values():\n",
    "    df = pd.read_csv(file, sep = '\\t', header = None)\n",
    "    accessions = list(df[1].values)\n",
    "    all_accessions = all_accessions + accessions\n",
    "    \n",
    "    newfile = file.replace('.out', '.refseq_list')\n",
    "    \n",
    "    if not os.path.exists(newfile):\n",
    "        with open(newfile, 'w+') as fileobj:\n",
    "            fileobj.writelines(acc + '\\n' for acc in accessions)\n",
    "\n",
    "all_accessions_set = set(all_accessions)\n",
    "\n",
    "outfile = '../output/TSP_Aam-RefSeq_hits.refseq_list'\n",
    "\n",
    "if not os.path.exists(outfile):\n",
    "    with open(outfile, 'w+') as fileobj:\n",
    "        fileobj.writelines(acc + '\\n' for acc in all_accessions_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Entry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIW62652.1</td>\n",
       "      <td>A0A0A0V684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TFK09892.1</td>\n",
       "      <td>A0A4D9ERY4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GFU45762.1</td>\n",
       "      <td>A0A8X6R426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIW62496.1</td>\n",
       "      <td>A0A0A0V9N6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KXN91798.1</td>\n",
       "      <td>A0A137QWX7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>XP_019635888.1</td>\n",
       "      <td>A0A6P4ZGM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>XP_018082512.1</td>\n",
       "      <td>A0A1L8FE91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>XP_016353901.1</td>\n",
       "      <td>A0A671KLV9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>XP_032046946.1</td>\n",
       "      <td>A0A6J3D6B3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>XP_016422484.1</td>\n",
       "      <td>A0A673I0P1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              From       Entry\n",
       "0       AIW62652.1  A0A0A0V684\n",
       "1       TFK09892.1  A0A4D9ERY4\n",
       "2       GFU45762.1  A0A8X6R426\n",
       "3       AIW62496.1  A0A0A0V9N6\n",
       "4       KXN91798.1  A0A137QWX7\n",
       "..             ...         ...\n",
       "48  XP_019635888.1  A0A6P4ZGM4\n",
       "49  XP_018082512.1  A0A1L8FE91\n",
       "50  XP_016353901.1  A0A671KLV9\n",
       "51  XP_032046946.1  A0A6J3D6B3\n",
       "52  XP_016422484.1  A0A673I0P1\n",
       "\n",
       "[168 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uniprot_idmm_results = ['../output/TSP_BLAST_to_EMBL-Genbank_DDBJ.tsv', '../output/TSP_BLAST_to_RefSeq.tsv']\n",
    "\n",
    "dummy_df = pd.DataFrame({'From':[], 'Entry':[]})\n",
    "\n",
    "for file in uniprot_idmm_results:\n",
    "    df = pd.read_csv(file, sep = '\\t')\n",
    "    sliced_df = df[['From', 'Entry']]\n",
    "    dummy_df = pd.concat([dummy_df, sliced_df])\n",
    "    \n",
    "dummy_df.drop_duplicates(inplace = True)\n",
    "display(dummy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_folder = bfd.Local / '20230331_test'\n",
    "alphafold_folder = output_folder / 'alphafold'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "if not os.path.exists(alphafold_folder):\n",
    "    os.mkdir(alphafold_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 165/165 [00:00<00:00, 63006.21it/s]\n"
     ]
    }
   ],
   "source": [
    "accessions = dummy_df['Entry'].unique().tolist()\n",
    "\n",
    "accessions_record_file = outfile.replace('.refseq_list', '.uniprot_list')\n",
    "\n",
    "if not os.path.exists(accessions_record_file):\n",
    "    with open(accessions_record_file, 'w+') as fileobj:\n",
    "        fileobj.writelines(acc + '\\n' for acc in accessions)\n",
    "\n",
    "for accession in tqdm(accessions):\n",
    "    output = alphafold_folder / 'AF-{}-F1-model_v4.pdb'.format(accession)\n",
    "    source = 'https://alphafold.ebi.ac.uk/files/AF-{}-F1-model_v4.pdb'.format(accession)\n",
    "    \n",
    "    if not os.path.exists(output):\n",
    "        subprocess.run(['curl' , '-JLo' , str(output), source], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keyfiles_dict = {\n",
    "    'blast_refseq_list': outfile,\n",
    "    'blast_uniprot_list': accessions_record_file,\n",
    "}\n",
    "\n",
    "inputfiles_dict = {f'TSP_hit{i}':file for i, file in enumerate(input_files)}\n",
    "outputfiles_dict = {f'TSP_blasthits{i}':file for i, file in enumerate(output_files)}\n",
    "\n",
    "keyfiles_dict = keyfiles_dict | inputfiles_dict | outputfiles_dict\n",
    "\n",
    "bfd.add_keyfiles(keyfiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://arcadia-protein-evolution/cartography/tsp/TSP_Aam-RefSeq_hits.refseq_list exists. Set overwrite = True to replace.\n",
      "s3://arcadia-protein-evolution/cartography/tsp/TSP_Aam-RefSeq_hits.uniprot_list exists. Set overwrite = True to replace.\n",
      "s3://arcadia-protein-evolution/cartography/tsp/TSP_Aam-1030859.txt exists. Set overwrite = True to replace.\n",
      "s3://arcadia-protein-evolution/cartography/tsp/TSP_Aam-2220.txt exists. Set overwrite = True to replace.\n",
      "s3://arcadia-protein-evolution/cartography/tsp/TSP_Aam-172335.txt exists. Set overwrite = True to replace.\n",
      "s3://arcadia-protein-evolution/cartography/tsp/TSP_Aam-1030859_blastp_results.out exists. Set overwrite = True to replace.\n",
      "s3://arcadia-protein-evolution/cartography/tsp/TSP_Aam-2220_blastp_results.out exists. Set overwrite = True to replace.\n",
      "s3://arcadia-protein-evolution/cartography/tsp/TSP_Aam-172335_blastp_results.out exists. Set overwrite = True to replace.\n",
      "s3://arcadia-protein-evolution/cartography/tsp/TSP_Aam.json exists. overwriting.\n",
      "upload: ../output/TSP_Aam.json to s3://arcadia-protein-evolution/cartography/tsp/TSP_Aam.json\n"
     ]
    }
   ],
   "source": [
    "bfd.local_to_s3()\n",
    "bfd.pickle()\n",
    "bfd.push_to_s3(overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identifier': 'TSP_Aam',\n",
       " 'local': '../output/',\n",
       " 'remote': 's3://arcadia-protein-evolution/cartography/tsp/',\n",
       " 'files': {},\n",
       " 'blast_refseq_list': <biofile.biofile.Biofile at 0x17af2b790>,\n",
       " 'blast_uniprot_list': <biofile.biofile.Biofile at 0x17af32150>,\n",
       " 'TSP_hit0': <biofile.biofile.Biofile at 0x17aede450>,\n",
       " 'TSP_hit1': <biofile.biofile.Biofile at 0x17aef1a10>,\n",
       " 'TSP_hit2': <biofile.biofile.Biofile at 0x17af284d0>,\n",
       " 'TSP_blasthits0': <biofile.biofile.Biofile at 0x17af2a890>,\n",
       " 'TSP_blasthits1': <biofile.biofile.Biofile at 0x17af55990>,\n",
       " 'TSP_blasthits2': <biofile.biofile.Biofile at 0x17af55b50>}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfd.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
